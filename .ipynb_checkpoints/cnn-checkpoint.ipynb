{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42f99c22-0c3b-4ad0-a8df-407b3f3959df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "import cv2 as cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eaa9004d-9349-4392-bc65-cadd49530039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "trainds = torchvision.datasets.CIFAR10(\n",
    "    root = \"./data\",\n",
    "    train = True,\n",
    "    transform = torchvision.transforms.ToTensor(),  \n",
    "    download = True\n",
    ")\n",
    "\n",
    "testds = torchvision.datasets.CIFAR10(\n",
    "    root = \"./data\",\n",
    "    train = False,\n",
    "    transform = torchvision.transforms.ToTensor(), \n",
    "    download = True\n",
    ")\n",
    "\n",
    "batch_size = 100\n",
    "\n",
    "trainldr = torch.utils.data.DataLoader(\n",
    "    dataset = trainds,\n",
    "    batch_size = batch_size,\n",
    "    shuffle = True\n",
    ")\n",
    "\n",
    "testldr = torch.utils.data.DataLoader(\n",
    "    dataset = testds,\n",
    "    batch_size = batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9bd3ab55-0135-4576-84d8-c39e4e5eb913",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_hwc = np.array(trainds[0][0] * 255).astype(np.uint8).transpose((1, 2, 0))\n",
    "img_hwc = cv.resize(img_hwc, (100, 100), interpolation = cv.INTER_LINEAR)\n",
    "\n",
    "#plt.imshow(img_hwc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3396ea06-6bca-4cc7-a48b-8c6699041a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class cnn(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.mxpul = torch.nn.MaxPool2d((2, 2), stride = 2)\n",
    "\n",
    "        self.convlay0 = torch.nn.Conv2d(3, 64, 3, stride = 1, padding = 'same')\n",
    "        self.convlay1 = torch.nn.Conv2d(64, 64, 3, stride = 1, padding = 'same')\n",
    "        self.convlay2 = torch.nn.Conv2d(64, 128, 3, stride = 1, padding = 'same')\n",
    "        self.convlay3 = torch.nn.Conv2d(128, 128, 3, stride = 1, padding = 'same')\n",
    "        self.convlay4 = torch.nn.Conv2d(128, 256, 3, stride = 1, padding = 'same')\n",
    "        self.convlay5 = torch.nn.Conv2d(256, 256, 3, stride = 1, padding = 'same')\n",
    "        self.convlay6 = torch.nn.Conv2d(256, 512, 3, stride = 1, padding = 'same')\n",
    "        self.convlay7 = torch.nn.Conv2d(512, 512, 3, stride = 1, padding = 'same')\n",
    "        self.convlay8 = torch.nn.Conv2d(512, 512, 3, stride = 1, padding = 'same')\n",
    "\n",
    "        self.linlay0 = torch.nn.Linear(512 * 4, 1024)\n",
    "        self.linlay1 = torch.nn.Linear(1024, 1024)\n",
    "        self.linlay2 = torch.nn.Linear(1024, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        out = F.relu(self.convlay0(x))\n",
    "        out = self.mxpul(F.relu(self.convlay1(out)))\n",
    "        out = F.relu(self.convlay2(out))\n",
    "        out = self.mxpul(F.relu(self.convlay3(out)))\n",
    "        out = F.relu(self.convlay4(out))\n",
    "        out = self.mxpul(F.relu(self.convlay5(out)))\n",
    "        out = F.relu(self.convlay6(out))\n",
    "        out = F.relu(self.convlay7(out))\n",
    "        out = self.mxpul(F.relu(self.convlay8(out)))\n",
    "        \n",
    "        out = out.view(-1, 512 * 2 * 2)\n",
    "        out = F.relu(self.linlay0(out))\n",
    "        out = F.relu(self.linlay1(out))\n",
    "        out = self.linlay2(out)\n",
    "        \n",
    "        return F.softmax(out, dim=1)\n",
    "#class cnn(torch.nn.Module):\n",
    "#    def __init__(self):\n",
    "#        super().__init__()\n",
    "#        \n",
    "#        self.mxpul = torch.nn.MaxPool2d((2, 2), stride = 1)\n",
    "#\n",
    "#        self.convlay0 = torch.nn.Conv2d(3, 64, 3, stride = 1)\n",
    "#        self.convlay1 = torch.nn.Conv2d(64, 128, 3, stride = 2)\n",
    "#        self.convlay2 = torch.nn.Conv2d(128, 128, 3, stride = 3)\n",
    "#\n",
    "#        self.linlay0 = torch.nn.Linear(1152, 300)\n",
    "#        self.linlay1 = torch.nn.Linear(300, 10)\n",
    "#    \n",
    "#    def forward(self, x):\n",
    "#\n",
    "#        out = self.mxpul(F.relu(self.convlay0(x)))\n",
    "#        out = self.mxpul(F.relu(self.convlay1(out)))\n",
    "#        out = self.mxpul(F.relu(self.convlay2(out)))\n",
    "#        out = out.view(-1, 128 * 3 * 3)\n",
    "#        out = F.relu(self.linlay0(out))\n",
    "#        out = self.linlay1(out)\n",
    "#        \n",
    "#        return F.softmax(out, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "523bad57-7ff9-4fb2-890f-873ab6eb8a48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is CUDA enabled? False\n",
      "cnn(\n",
      "  (mxpul): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (convlay0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "  (convlay1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "  (convlay2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "  (convlay3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "  (convlay4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "  (convlay5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "  (convlay6): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "  (convlay7): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "  (convlay8): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "  (linlay0): Linear(in_features=2048, out_features=1024, bias=True)\n",
      "  (linlay1): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "  (linlay2): Linear(in_features=1024, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = cnn()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f519e4e-768a-43d7-b90a-69f8544f14e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8863284c-ed31-4d3b-9ed0-892944717047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n"
     ]
    }
   ],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "print(len(trainldr.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fed9b8e2-af91-4732-be5d-5d9147102591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number epoch: 1 \t epoch execution time: 244.19639039039612 \t  mean_loss: 0.023025887086987495\n",
      "number epoch: 2 \t epoch execution time: 256.7474799156189 \t  mean_loss: 0.02302587404847145\n",
      "number epoch: 3 \t epoch execution time: 257.7462751865387 \t  mean_loss: 0.023025866597890854\n",
      "number epoch: 4 \t epoch execution time: 261.7996048927307 \t  mean_loss: 0.0230258759111166\n",
      "number epoch: 5 \t epoch execution time: 322.5918209552765 \t  mean_loss: 0.023025883361697197\n",
      "number epoch: 6 \t epoch execution time: 286.6722548007965 \t  mean_loss: 0.0230258796364069\n",
      "number epoch: 7 \t epoch execution time: 238.62143206596375 \t  mean_loss: 0.023025866597890854\n",
      "number epoch: 8 \t epoch execution time: 239.38139033317566 \t  mean_loss: 0.0230258721858263\n",
      "number epoch: 9 \t epoch execution time: 237.05193090438843 \t  mean_loss: 0.0230258721858263\n",
      "number epoch: 10 \t epoch execution time: 239.52543377876282 \t  mean_loss: 0.02302587404847145\n",
      "number epoch: 11 \t epoch execution time: 239.3646056652069 \t  mean_loss: 0.023025861009955406\n",
      "number epoch: 12 \t epoch execution time: 237.48429226875305 \t  mean_loss: 0.023025859147310257\n",
      "number epoch: 13 \t epoch execution time: 237.78378915786743 \t  mean_loss: 0.023025866597890854\n",
      "number epoch: 14 \t epoch execution time: 237.00042843818665 \t  mean_loss: 0.023025868460536003\n",
      "number epoch: 15 \t epoch execution time: 236.53481316566467 \t  mean_loss: 0.023025881499052048\n",
      "number epoch: 16 \t epoch execution time: 236.73192310333252 \t  mean_loss: 0.023025861009955406\n",
      "number epoch: 17 \t epoch execution time: 237.60530757904053 \t  mean_loss: 0.0230258796364069\n",
      "number epoch: 18 \t epoch execution time: 239.62158727645874 \t  mean_loss: 0.0230258721858263\n",
      "number epoch: 19 \t epoch execution time: 240.0882170200348 \t  mean_loss: 0.02302587404847145\n",
      "number epoch: 20 \t epoch execution time: 239.94166469573975 \t  mean_loss: 0.0230258796364069\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    start_time = time.time()\n",
    "    mean_loss = 0\n",
    "    for data, labels in trainldr:\n",
    "        data, labels = Variable(data), Variable(labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        net_out = net(data)\n",
    "        loss = criterion(net_out, labels)\n",
    "        mean_loss += loss.data\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(\"number epoch: {} \\t epoch execution time: {} \\t  mean_loss: {}\".format(\n",
    "        epoch + 1, time.time() - start_time, mean_loss / len(trainldr.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "56ef7545-885b-40c4-b616-dc05e759ef5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nTest set: Average loss: 0.0230, Accuracy: 2000/10000 (20%)\n"
     ]
    }
   ],
   "source": [
    "test_loss = 0\n",
    "correct = 0\n",
    "for data, labels in testldr:\n",
    "    data, labels = Variable(data), Variable(labels)\n",
    "    net_out = net(data)\n",
    "    test_loss += criterion(net_out, labels).data\n",
    "    for ind, t in enumerate(net_out):\n",
    "        mxind1, mxind2 = 0, 1\n",
    "        for ind2, x in enumerate(t):\n",
    "            if t[ind2] > t[mxind1]:\n",
    "                mxind2 = mxind1\n",
    "                mxind1 = ind2\n",
    "            elif ind2 != mxind1 and t[ind2] > t[mxind2]:\n",
    "                mxind2 = ind2\n",
    "        if labels[ind] == mxind1 or labels[ind] == mxind2:\n",
    "            correct += 1\n",
    "   \n",
    "\n",
    "test_loss /= len(testldr.dataset)\n",
    "print('nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)'.format(\n",
    "       test_loss, correct, len(testldr.dataset),\n",
    "       100. * correct / len(testldr.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38010947-8397-4aea-99ee-1194bcb3d4ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
